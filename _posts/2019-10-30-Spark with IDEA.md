---
layout:     post
title:   Spark with IDEA
subtitle:   å¤§æ•°æ®å¤„ç†
date:       2019-10-18
author:     Yi Xia
header-img: img/post-bg-BJJ.jpg
catalog: true
tags:
    - Java
---

# Spark with IDEA
IDEA å…¨ç§° IntelliJ IDEAï¼Œæ˜¯javaè¯­è¨€å¼€å‘çš„é›†æˆç¯å¢ƒï¼ŒIntelliJåœ¨ä¸šç•Œè¢«å…¬è®¤ä¸ºæœ€å¥½çš„Javaå¼€å‘å·¥å…·ä¹‹ä¸€, IDEAæ˜¯JetBrainså…¬å¸çš„äº§å“,ç°åœ¨æœ‰é€æ­¥å–ä»£è€ç‰ŒJavaå¼€å‘å·¥å…·Eclipseçš„è¶‹åŠ¿.é‚£æœ¬äººä¹Ÿæ˜¯ä»Eclipse è½¬åˆ°IDEA.é‚£åˆšè½¬æ¢è¿‡æ¥æ—¶,ç¡®å®å¾ˆä¸é€‚åº”,ä¸è¿‡å¥½åœ¨åšæŒä½¿ç”¨äº†å‡ å¤©å,ç¡®å®æ„Ÿè§‰IntelliJ IDEAæ¯”Eclipseæ›´åŠ æ™ºèƒ½.
Mavené¡¹ç›®å¯¹è±¡æ¨¡å‹(POM)ï¼Œæ˜¯ä¸€ä¸ªé¡¹ç›®ç®¡ç†å·¥å…·å¯ä»¥é€šè¿‡ä¸€å°æ®µæè¿°ä¿¡æ¯æ¥ç®¡ç†é¡¹ç›®çš„æ„å»ºï¼ŒæŠ¥å‘Šå’Œæ–‡æ¡£çš„è½¯ä»¶ã€‚é‚£æˆ‘ä»¬æƒ³è¦åœ¨IDEAä¸­ä½¿ç”¨Mavenå¾—è¿›è¡Œä¸€äº›é…ç½®,é‚£æ¥ä¸‹æ¥
æˆ‘ä»¬å…·ä½“çœ‹ä¸€ä¸‹æ˜¯å¦‚ä½•é…ç½®ä½¿ç”¨çš„?
## Maven
å› ä¸ºæ­å»ºè¿™ä¸ªSpark with IDEAï¼Œä»¥å‰ä»æ²¡æ‘¸è¿‡ mavenï¼Œè¿™æ¬¡å€Ÿæ­¤æ¥å­¦äº†ä¸€ä¸‹åŸºç¡€çŸ¥è¯†
å…·ä½“çš„ä»‹ç»è§æˆ‘å¦ä¸€ç¯‡ blog
[http://summerone.xyz/2019/10/18/IDEA-with-Maven/](http://summerone.xyz/2019/10/18/IDEA-with-Maven/)
mavenæ˜¯ä¸€æ¬¾ä¼˜ç§€çš„æœåŠ¡æ„å»ºå·¥å…·ï¼ŒåŸºäºçº¦å®šä¼˜äºé…ç½®åŸåˆ™ï¼Œæä¾›æ ‡å‡†çš„æœåŠ¡æ„å»ºæµç¨‹ã€‚mavençš„ä¼˜ç‚¹ä¸ä»…é™äºæœåŠ¡æ„å»ºï¼Œä½¿ç”¨mavenèƒ½å¤Ÿåšåˆ°é«˜æ•ˆçš„ä¾èµ–ç®¡ç†ï¼Œå¹¶ä¸”æä¾›æœ‰ä¸­å¤®ä»“åº“å¯ä»¥å®Œæˆç»å¤§å¤šæ•°ä¾èµ–çš„ä¸‹è½½ä½¿ç”¨ã€‚


![-w680](/img/blog_img/15724225884585.jpg)

mavenè‡ªèº«æä¾›æœ‰ä¸°å¯Œçš„æ’ä»¶ï¼Œå¯ä»¥åœ¨ä¸ä½¿ç”¨é¢å¤–æ’ä»¶çš„æ¡ä»¶ä¸‹å®ŒæˆæœåŠ¡çš„ç¼–è¯‘ã€æµ‹è¯•ã€æ‰“åŒ…ã€éƒ¨ç½²ç­‰æœåŠ¡æ„å»ºæµç¨‹ï¼Œå³mavenå¯¹æœåŠ¡çš„æ„å»ºè¿‡ç¨‹æ˜¯é€šè¿‡å¤šä¸ªæ’ä»¶å®Œæˆçš„ï¼Œä¸”mavenå·²ç»è‡ªå®šä¹‰äº†æ’ä»¶çš„è¡Œä¸ºã€‚å¯ä»¥ç†è§£ä¸ºæ¯ä¸€ä¸ªæ’ä»¶éƒ½æ˜¯å¯¹æ¥å£çš„å®ç°ï¼Œå¯ä»¥è‡ªå®šä¹‰æ’ä»¶ï¼Œä»¥å®Œæˆè‡ªå®šä¹‰åŠŸèƒ½ï¼Œä¾‹å¦‚å®Œæˆå¯¹ä¸åŒç¼–ç¨‹è¯­è¨€çš„æœåŠ¡æ„å»ºè¿‡ç¨‹ã€‚ä¸è¿‡ç›¸å¯¹äºgradleçš„è‡ªå®šä¹‰æ’ä»¶è¡Œä¸ºï¼Œmavençš„å®ç°è¿‡ç¨‹ç•¥å¾®å¤æ‚ã€‚

## Spark with IDEAæ­å»ºç¯å¢ƒ
- é¦–å…ˆå®‰è£…Scalaæ’ä»¶ï¼ŒFile->Settings->Pluginsï¼Œæœç´¢å‡ºSclaæ’ä»¶ï¼Œç‚¹å‡»Installå®‰è£…ï¼›ï¼ˆé€Ÿåº¦æ¯”è¾ƒæ…¢ï¼Œå¯ä»¥è¯•è¯•å…¶ä»–çš„æºï¼Œä¸ç”¨å®˜ç½‘çš„ï¼‰
![-w965](/img/blog_img/15724978721026.jpg)

- File->New Project->mavenï¼Œæ–°å»ºä¸€ä¸ªMavené¡¹ç›®ï¼Œå¡«å†™GroupIdå’ŒArtifactId
![-w963](/img/blog_img/15724979023965.jpg)
![-w960](/img/blog_img/15724979415442.jpg)

> è¿™é‡Œç»™å¤§å®¶æ™®åŠä¸€ä¸‹è¿™ä¸¤ä¸ªçš„ä½œç”¨ï¼š
> groupidå’ŒartifactIdè¢«ç»Ÿç§°ä¸ºâ€œåæ ‡â€æ˜¯ä¸ºäº†ä¿è¯é¡¹ç›®å”¯ä¸€æ€§è€Œæå‡ºçš„ï¼Œå¦‚æœä½ è¦æŠŠä½ é¡¹ç›®å¼„åˆ°mavenæœ¬åœ°ä»“åº“å»ï¼Œä½ æƒ³è¦æ‰¾åˆ°ä½ çš„é¡¹ç›®å°±å¿…é¡»æ ¹æ®è¿™ä¸¤ä¸ªidå»æŸ¥æ‰¾ã€‚ 
ã€€ã€€groupIdä¸€èˆ¬åˆ†ä¸ºå¤šä¸ªæ®µï¼Œè¿™é‡Œæˆ‘åªè¯´ä¸¤æ®µï¼Œç¬¬ä¸€æ®µä¸ºåŸŸï¼Œç¬¬äºŒæ®µä¸ºå…¬å¸åç§°ã€‚åŸŸåˆåˆ†ä¸ºorgã€comã€cnç­‰ç­‰è®¸å¤šï¼Œå…¶ä¸­orgä¸ºéè¥åˆ©ç»„ç»‡ï¼Œcomä¸ºå•†ä¸šç»„ç»‡ã€‚ä¸¾ä¸ªapacheå…¬å¸çš„tomcaté¡¹ç›®ä¾‹å­ï¼šè¿™ä¸ªé¡¹ç›®çš„groupIdæ˜¯org.apacheï¼Œå®ƒçš„åŸŸæ˜¯orgï¼ˆå› ä¸ºtomcatæ˜¯éè¥åˆ©é¡¹ç›®ï¼‰ï¼Œå…¬å¸åç§°æ˜¯apacheï¼ŒartigactIdæ˜¯tomcatã€‚ 
ã€€ã€€artifactä½ æŠŠå®ƒç†è§£æˆâ€œç”Ÿæˆçš„ä¸œè¥¿â€å°±å·®ä¸å¤šäº†ã€‚è¿™ä¸ªè¯å¼ºè°ƒçš„æ˜¯è¿™æ˜¯ä½ è½¯ä»¶ç”Ÿäº§è¿‡ç¨‹ä¸­æŸä¸€æ­¥çš„äº§ç”Ÿç‰©ï¼Œä¸åƒç¨‹åºæœ¬èº«ï¼Œæˆ–è€…æ˜¯é…ç½®æ–‡ä»¶è¿™äº›ï¼Œæ˜¯ä½ æ‰‹å†™å‡ºæ¥çš„ã€‚
ã€€ã€€






- ä¸ºæˆ‘ä»¬çš„mavenå·¥ç¨‹ï¼Œå¯¼å…¥sdkç¯å¢ƒ

>  ç‰¹åˆ«æ³¨æ„è¿™é‡Œçš„scala ç¯å¢ƒå°±æ˜¯ä½ çš„ spark ç¯å¢ƒçš„ scala ç‰ˆæœ¬ï¼Œä¸è¦ä¸‹é”™äº†

![-w1118](/img/blog_img/15724983946809.jpg)

- è¿™ä¸ªå¯¼å…¥å®Œæ¯•ä¹‹åï¼ŒåŸºæœ¬ç¯å¢ƒå°±æ­å»ºå®Œæ¯•äº†ï¼Œæ¥ä¸‹æ¥ï¼Œä¿®æ”¹pomæ–‡ä»¶ï¼Œå¢æ·»æˆ‘ä»¬çš„spark-coreã€‚

```shell
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>test</groupId>
    <artifactId>test</artifactId>
    <version>1.0-SNAPSHOT</version>
    <properties>
        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
        <spark.version>2.4.4</spark.version>
        <scala.version>2.11.12</scala.version>
        <hadoop.version>2.8.5</hadoop.version>
    </properties>

    <dependencies>
        <!-- https://mvnrepository.com/artifact/org.apache.spark/spark-core_2.11 -->
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.version}</artifactId>
            <version>${spark.version}</version>
<!--            <scope>provided</scope>-->
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-client</artifactId>
            <version>2.7.3</version>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-mllib_${scala.version}</artifactId>
            <version>${spark.version}</version>
        </dependency>
        <dependency>
            <groupId>mysql</groupId>
            <artifactId>mysql-connector-java</artifactId>
            <version>5.1.39</version>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>4.12</version>
        </dependency>
    </dependencies>

    <repositories>
        <repository>
            <id>central</id>
            <name>Maven Repository Switchboard</name>
            <layout>default</layout>
            <url>http://repo2.maven.org/maven2</url>
            <snapshots>
                <enabled>false</enabled>
            </snapshots>
        </repository>
    </repositories>

    <build>
        <sourceDirectory>src/main/scala</sourceDirectory>
        <testSourceDirectory>src/test/scala</testSourceDirectory>

        <plugins>
            <plugin>
                <!-- MAVEN ç¼–è¯‘ä½¿ç”¨çš„JDKç‰ˆæœ¬ -->
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <version>3.5</version>
                <configuration>
                    <source>1.8</source>
                    <target>1.8</target>
                    <encoding>UTF-8</encoding>
                </configuration>
            </plugin>
        </plugins>
    </build>

</project>
```

> å…¶ä¸­è¯•äº†å‡ æ¬¡ï¼Œspark æºç çš„åŒ…ä¹Ÿæ²¡æ³•å¼•å…¥ï¼Œæœ€ç»ˆç›´æ¥æŠŠ spark æºç é‡Œçš„ jars åŒ…ç›´æ¥åŠ åˆ°äº† library é‡Œï¼Œç®€å•ç²—æš´ğŸ¤Ÿã€‚
![-w1118](/img/blog_img/15724995365553.jpg)


## æµ‹è¯•

```scala
import scala.math.random
import org.apache.spark._

object SparkPi {
  def main(args: Array[String]) {
    //val conf = new SparkConf().setAppName("Spark Pi").setMaster("spark://192.168.189.136:7077").setJars(List("D:\\scala\\sparkjar\\sparktest.jar"))
    //val spark = new SparkContext("spark://master:7070", "Spark Pi", "F:\\soft\\spark\\spark-1.1.0-bin-hadoop2.4", List("out\\artifacts\\sparkTest_jar\\sparkTest.jar"))
    val conf = new SparkConf().setAppName("Spark Pi").setMaster("local")//ä¸»è¦æ˜¯è¿™å¥
    val spark = new SparkContext(conf)
    val slices = if (args.length > 0) args(0).toInt else 2
    val n = 100000 * slices
    val count = spark.parallelize(1 to n, slices).map { i =>
      val x = random * 2 - 1
      val y = random * 2 - 1
      if (x * x + y * y < 1) 1 else 0
    }.reduce(_ + _)
    println("Pi is roughly " + 4.0 * count / n)
    spark.stop()
  }
}

```

- File->Project Structure->Artifactsï¼Œæ–°å»ºä¸€ä¸ªJar->From modules with dependencies...ï¼Œé€‰æ‹©Main Classï¼š

![-w1118](/img/blog_img/15724993445203.jpg)

- Build->Build Artifacts...ï¼Œç”Ÿæˆjarï¼Œç¨åæ”¾åˆ°é›†ç¾¤ä¸Šè¿è¡Œä¹Ÿæ˜¯å¯ä»¥
 ![-w1552](/img/blog_img/15724994497622.jpg)

![-w1440](/img/blog_img/15724233597915.jpg)

- ç„¶åå†è¿è¡Œï¼ŒæˆåŠŸï¼
![-w1552](/img/blog_img/15724235313794.jpg)
![-w594](/img/blog_img/15724236824857.jpg)

```scala
import org.apache.spark.{SparkConf, SparkContext}object TopN {  def main(args: Array[String]): Unit = {    val conf = new SparkConf().setAppName("TopN").setMaster("local")    val sc = new SparkContext(conf)    sc.setLogLevel("ERROR")    val lines = sc.textFile("hdfs://localhost:9000/user/hadoop/spark/mycode/rdd/examples",2)    var num = 0;    val result = lines.filter(line => (line.trim().length > 0) && (line.split(",").length == 4))      .map(_.split(",")(2))      .map(x => (x.toInt,""))      .sortByKey(false)      .map(x => x._1).take(5)      .foreach(x => {        num = num + 1        println(num + "\t" + x)      })  }}
```
![-w1552](/img/blog_img/15724235760541.jpg)



![-w1552](/img/blog_img/15724234435017.jpg)

![-w1440](/img/blog_img/15724233597915.jpg)

## å‘
- æ³¨æ„é›†ç¾¤çš„ scala çš„ç‰ˆæœ¬å’Œä½ çš„æœ¬æœºçš„ scala çš„ç‰ˆæœ¬åº”è¯¥æ˜¯ä¸€æ ·çš„
![-w777](/img/blog_img/15726061209304.jpg)

- java.lang.NoClassDefFoundError: org/apache/spark/streaming/dstream/DStream 

```shell
<dependency>
        <groupId>org.apache.spark</groupId>
        <artifactId>spark-streaming_2.11</artifactId>
        <version>2.3.1</version>
        <!--<scope>provided</scope>-->
    </dependency>
```
ç»è¿‡æŸ¥é˜…èµ„æ–™ï¼Œè¿™ä¸ªé”™è¯¯çš„äº§ç”ŸåŸå› æ˜¯ï¼ŒMavenåº“ä¸­SparkSteamingçš„Scopeé»˜è®¤æ˜¯Providedçš„ï¼Œå› æ­¤åœ¨è¿è¡Œçš„æ—¶å€™å®é™…ä¸Šå¹¶ä¸ä¼šåŒ…å«SparkSteamingç›¸å…³çš„JaråŒ…ã€‚å› æ­¤ï¼ŒæŠŠScopeåˆ å»ï¼Œæˆ–è€…æ”¹ä¸ºCompileå³å¯ï¼ˆé»˜è®¤å³ä¸ºCompileï¼‰ã€‚

