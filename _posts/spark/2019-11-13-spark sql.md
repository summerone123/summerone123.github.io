---
layout:     post
title:     Spark sql
subtitle:   å¤§æ•°æ®å¤„ç†
date:       2019-10-16
author:     Yi Xia
header-img: img/post-bg-map.jpg
catalog: true
tags:
    - å¤§æ•°æ®å¤„ç†
---

# spark sql

## Spark SQLåŸºæœ¬æ“ä½œ
å°†ä¸‹åˆ—jsonæ•°æ®å¤åˆ¶åˆ°ä½ çš„ç³»ç»Ÿ/usr/local/sparkä¸‹ï¼Œå¹¶ä¿å­˜å‘½åä¸ºemployee.json

```
{ "id":1 ,"name":" Ella","age":36 }
{ "id":2,"name":"Bob","age":29 }
{ "id":3 ,"name":"Jack","age":29 }
{ "id":4 ,"name":"Jim","age":28 }
{ "id":5 ,"name":"Damon" }
{ "id":5 ,"name":"Damon" }
```

é¦–å…ˆä¸ºemployee.jsonåˆ›å»ºDataFrameï¼Œå¹¶å†™å‡ºScalaè¯­å¥å®Œæˆä¸‹åˆ—æ“ä½œï¼š
åˆ›å»ºDataFrame

```
(1)æŸ¥è¯¢DataFrameçš„æ‰€æœ‰æ•°æ®
(2)æŸ¥è¯¢æ‰€æœ‰æ•°æ®ï¼Œå¹¶åŽ»é™¤é‡å¤çš„æ•°æ®
(3)æŸ¥è¯¢æ‰€æœ‰æ•°æ®ï¼Œæ‰“å°æ—¶åŽ»é™¤idå­—æ®µ
(4)ç­›é€‰age>20çš„è®°å½•
(5)å°†æ•°æ®æŒ‰nameåˆ†ç»„
(6)å°†æ•°æ®æŒ‰nameå‡åºæŽ’åˆ—
(7)å–å‡ºå‰3è¡Œæ•°æ®
(8)æŸ¥è¯¢æ‰€æœ‰è®°å½•çš„nameåˆ—ï¼Œå¹¶ä¸ºå…¶å–åˆ«åä¸ºusername
(9)æŸ¥è¯¢å¹´é¾„ageçš„å¹³å‡å€¼
(10)æŸ¥è¯¢å¹´é¾„ageçš„æœ€å°å€¼
```

### å¯¼å…¥ç›¸å…³åº“åŠè¯»å…¥æ•°æ®
```scala
scala> import org.apache.spark.sql.SparkSession

scala> val spark=SparkSession.builder().getOrCreate()

scala> import spark.implicits._

scala> val df = spark.read.json("file:////home/bd2016/soft/employee.json")

```
æ­¤å¤„æ³¨æ„è·¯å¾„è¦å†™æˆç»å¯¹è·¯å¾„ï¼Œå¹¶ä¸”æ³¨æ„å†™å…¥çš„æœ¬åœ°æ–‡ä»¶æ ¼å¼ï¼ˆå…·ä½“ä¸ºç«¯å£çš„é—®é¢˜ï¼‰
### ç›¸å…³æ“ä½œ
- (1)æŸ¥è¯¢DataFrameçš„æ‰€æœ‰æ•°æ®

```
df.show()
```

```
scala> df.show()
+----+---+-----+
| age| id| name|
+----+---+-----+
|  36|  1| Ella|
|  29|  2|  Bob|
|  29|  3| Jack|
|  28|  4|  Jim|
|null|  5|Damon|
|null|  5|Damon|
+----+---+-----+
```

- (2)æŸ¥è¯¢æ‰€æœ‰æ•°æ®ï¼Œå¹¶åŽ»é™¤é‡å¤çš„æ•°æ®

```
scala> df.distinct.show()
+----+---+-----+
| age| id| name|
+----+---+-----+
|  36|  1| Ella|
|  29|  3| Jack|
|null|  5|Damon|
|  29|  2|  Bob|
|  28|  4|  Jim|
+----+---+-----+

```
- (3)æŸ¥è¯¢æ‰€æœ‰æ•°æ®ï¼Œæ‰“å°æ—¶åŽ»é™¤idå­—æ®µ

```
scala> df.drop("id").show()
+----+-----+
| age| name|
+----+-----+
|  36| Ella|
|  29|  Bob|
|  29| Jack|
|  28|  Jim|
|null|Damon|
|null|Damon|
+----+-----+

```
- (4)ç­›é€‰age>20çš„è®°å½•

```
scala> df.filter(df("age")>20).show()
+---+---+-----+
|age| id| name|
+---+---+-----+
| 36|  1| Ella|
| 29|  2|  Bob|
| 29|  3| Jack|
| 28|  4|  Jim|
+---+---+-----+

```
- (5)å°†æ•°æ®æŒ‰nameåˆ†ç»„

```
scala> df.groupBy("name").count.show()
+-----+-----+
| name|count|
+-----+-----+
|Damon|    2|
| Ella|    1|
|  Jim|    1|
| Jack|    1|
|  Bob|    1|
+-----+-----+

```
æ³¨æ„:
- ` groupBy`çš„ B æ˜¯å¤§å†™
- ä¸èƒ½ç›´æŽ¥scala> df.groupBy("name").show()ï¼ŒgroupBy æ˜¯è½¬æ¢æ“ä½œï¼Œåªæœ‰action æ‰å¯ä»¥ showï¼ˆï¼‰

```
scala> df.groupBy("name").show()
<console>:32: error: value show is not a member of org.apache.spark.sql.RelationalGroupedDataset
       df.groupBy("name").show()
                          ^
```

- (6)å°†æ•°æ®æŒ‰nameå‡åºæŽ’åˆ—

```
scala> df.sort(df("name").asc).show()
+----+---+-----+
| age| id| name|
+----+---+-----+
|  36|  1| Ella|
|  29|  2|  Bob|
|null|  5|Damon|
|null|  5|Damon|
|  29|  3| Jack|
|  28|  4|  Jim|
+----+---+-----+

```
- (7)å–å‡ºå‰3è¡Œæ•°æ®

```
scala> df.head(3)
res16: Array[org.apache.spark.sql.Row] = Array([36,1, Ella], [29,2,Bob], [29,3,Jack])

```
- (8)æŸ¥è¯¢æ‰€æœ‰è®°å½•çš„nameåˆ—ï¼Œå¹¶ä¸ºå…¶å–åˆ«åä¸ºusername

```
scala> df.select(df("name").as("username")).show()
+--------+
|username|
+--------+
|    Ella|
|     Bob|
|    Jack|
|     Jim|
|   Damon|
|   Damon|
+--------+

```
- (9)æŸ¥è¯¢å¹´é¾„ageçš„å¹³å‡å€¼

è¿™ä¸¤ä¸ªï¼ˆ9ï¼‰ï¼ˆ10ï¼‰è¿ç”¨ describe éƒ½èƒ½ä¸€æ¬¡è¾“å‡ºï¼Œç®€å•é«˜æ•ˆ
```
scala> df.describe("age").show()
+-------+-----------------+
|summary|              age|
+-------+-----------------+
|  count|                4|
|   mean|             30.5|
| stddev|3.696845502136472|
|    min|               28|
|    max|               36|
+-------+-----------------+
```


- (10)æŸ¥è¯¢å¹´é¾„ageçš„æœ€å°å€¼

```
scala> df.describe("age").show()
+-------+-----------------+
|summary|              age|
+-------+-----------------+
|  count|                4|
|   mean|             30.5|
| stddev|3.696845502136472|
|    min|               28|
|    max|               36|
+-------+-----------------+
```
åŒæ—¶é™„ä¸€ä¸ªæˆ‘è§‰å¾—æ¯”è¾ƒå¥½çš„`Spark-SQLä¹‹DataFrameæ“ä½œå¤§å…¨`ï¼Œå¢žåŠ ä¸€ä¸‹ä»–çš„ pagerank å€¼ï¼Œæ€Žä¹ˆè¯´å’±ä¹Ÿæ˜¯æƒå¨é¡µé¢Â ðŸ§
[Spark-SQLä¹‹DataFrameæ“ä½œå¤§å…¨](https://blog.csdn.net/dabokele/article/details/52802150)

## ç¼–ç¨‹å®žçŽ°å°†RDDè½¬æ¢ä¸ºDataFrame
æ–‡ä»¶å†…å®¹å¦‚ä¸‹ï¼ˆåŒ…å«id,name,ageï¼‰ï¼Œå°†æ•°æ®å¤åˆ¶ä¿å­˜åˆ°ç³»ç»Ÿ/usr/local/sparkä¸‹ï¼Œå‘½åä¸ºemployee.txtï¼Œå®žçŽ°ä»ŽRDDè½¬æ¢å¾—åˆ°DataFrameï¼Œå¹¶æŒ‰id:1,name:Ella,age:36çš„æ ¼å¼æ‰“å°å‡ºDataFrameçš„æ‰€æœ‰æ•°æ®ã€‚è¯·å†™å‡ºç¨‹åºä»£ç ã€‚ï¼ˆä»»é€‰ä¸€ç§æ–¹æ³•å³å¯ï¼‰

```
1,Ella,36 
2,Bob,29
3,Jack,29
```

![-w1440](/img/blog_img/15736090469675.jpg)

åŒæ—¶ä¹Ÿå¯ä»¥å°†å…¶æ‰“æˆ jaråŒ…ï¼Œæ‰”åˆ°é›†ç¾¤ä¸Šï¼Œsummit è¿è¡Œå³å¯
```
spark-submit --class RDDtoDF ~/test.jar 
```
![-w876](/img/blog_img/15736096600381.jpg)

### æºä»£ç åŠè§£æž
```scala
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder
import org.apache.spark.sql.Encoder
import org.apache.spark.sql.SparkSession

object RDDtoDF {
  case class Employee(id:Long,name: String, age: Long)//æ”¾åˆ° main å‡½æ•°çš„å¤–é¢ï¼Œè§£å†³value toDF is not a member of org.apache.spark.rdd.RDD
  def main(args: Array[String]) {
    val conf = new SparkConf().setAppName("Student").setMaster("local")
    val sc = new SparkContext(conf)
    val spark=  SparkSession.builder()
      .appName("Spark Sql basic example")
      .config("spark.some.config.option", "some-value")
      .getOrCreate()

    import spark.implicits._


    val employeeDF = spark.sparkContext.textFile("file:///Users/summerone/Desktop/spark/employee.txt").map(_.split(",")).map(attributes=>Employee(attributes(0).trim.toInt,attributes(1), attributes(2).trim.toInt)).toDF()

    employeeDF.createOrReplaceTempView("employee")
    val employeeRDD = spark.sql("select id,name,age from employee")
    employeeRDD.map(t=>"id:"+t(0)+","+"name:"+t(1)+","+"age:"+t(2)).show()

  }

}            
```
### æ³¨æ„äº‹é¡¹ï¼š
- æ— æ³•å¯¼å…¥`spark.implicits._`
    - è§£å†³æ–¹æ³•ï¼šå°†  import spark.implicits._ æ”¾åˆ° def main(args: Array[String])ä¸­ï¼Œå¹¶åœ¨å‰é¢æå‰å®šä¹‰SparkSession.builder()
    
```
val spark=  SparkSession.builder()
      .appName("Spark Sql basic example")
      .config("spark.some.config.option", "some-value")
      .getOrCreate()

    import spark.implicits._
```

- value toDF is not a member of org.apache.spark.rdd.RDD
    - è§£å†³æ–¹æ³•ï¼šä¸¤ç§è§£å†³æ–¹æ³•
        - import sqlContext.implicits._ è¯­å¥éœ€è¦æ”¾åœ¨èŽ·å–sqlContextå¯¹è±¡çš„è¯­å¥ä¹‹åŽ

        - case class People(name : String, age : Int) çš„å®šä¹‰éœ€è¦æ”¾åœ¨æ–¹æ³•çš„ä½œç”¨åŸŸä¹‹å¤–ï¼ˆå³Javaçš„æˆå‘˜å˜é‡ä½ç½®ï¼‰ 


## ç¼–ç¨‹å®žçŽ°åˆ©ç”¨DataFrameè¯»å†™MySQLçš„æ•°æ®
### (1)åœ¨MySQLæ•°æ®åº“ä¸­æ–°å»ºæ•°æ®åº“sparktestï¼Œå†å»ºè¡¨employeeï¼ŒåŒ…å«ä¸‹åˆ—ä¸¤è¡Œæ•°æ®ï¼›
è¡¨1 employeeè¡¨åŽŸæœ‰æ•°æ®

| id | name | gender | age |
| --- | --- | --- | --- |
| 1 | Alice | F | 22 |
| 2 | John | M | 25  |


```sql
mysql> create database sparktest;
Query OK, 1 row affected (0.00 sec)

mysql> use sparktest;
Database changed
mysql> create table employee (id int(4), name char(20), gender char(4), age int(4));
Query OK, 0 rows affected (0.02 sec)

mysql> insert into employee values(1,'Alice','F',22);
Query OK, 1 row affected (0.01 sec)

mysql> insert into employee values(2,'John','M',25);
Query OK, 1 row affected (0.01 sec)
```


```
mysql> show tables;
+---------------------+
| Tables_in_sparktest |
+---------------------+
| employee            |
+---------------------+
1 row in set (0.01 sec)
```


### (2)é…ç½®Sparké€šè¿‡JDBCè¿žæŽ¥æ•°æ®åº“MySQLï¼Œç¼–ç¨‹å®žçŽ°åˆ©ç”¨DataFrameæ’å…¥ä¸‹åˆ—æ•°æ®åˆ°MySQLï¼Œæœ€åŽæ‰“å°å‡ºageçš„æœ€å¤§å€¼å’Œageçš„æ€»å’Œã€‚
è¡¨2 employeeè¡¨æ–°å¢žæ•°æ®

| id | name | gender | age |
| --- | --- | --- | --- |
| 3 | Mary | F | 26 |
| 4 | Tom | M | 23  |

#### IDEAé…ç½®JDBC ï¼Œè¿žæŽ¥æœ¬åœ° mysql
- ä¸‹è½½ jar åŒ…
![-w1066](/img/blog_img/15737318028452.jpg)

- æµ‹è¯•è¿žæŽ¥ï¼ˆç»¿è‰²å¸¦è¾¹ jdbc è¿žæŽ¥æˆåŠŸï¼‰
![-w1183](/img/blog_img/15737318731328.jpg)

- è§‚æµ‹ï¼ˆ1ï¼‰ä¸­åˆ›å»ºçš„æ•°æ®åº“åŠæ’å…¥çš„æ•°æ®
![-w465](/img/blog_img/15737338202251.jpg)

#### ç¼–ç¨‹å®žçŽ°åˆ©ç”¨ DataFrame æ’å…¥ä¸‹åˆ—æ•°æ®åˆ° MySQLï¼Œæœ€åŽæ‰“å°å‡º age çš„æœ€å¤§å€¼å’Œ age çš„æ€»å’Œ


![-w1440](/img/blog_img/15737339644770.jpg)
![-w1440](/img/blog_img/15737340404298.jpg)
![-w1440](/img/blog_img/15737341575284.jpg)

#### æºç åŠå…¶è§£æžï¼ˆå°†å¯†ç ä¸Žç”¨æˆ·æ”¹æˆè‡ªå·±çš„å³å¯ï¼‰
```scala
import org.apache.spark.{SparkConf, SparkContext}
import org.apache.spark.sql.types._
import org.apache.spark.sql.{Row, SparkSession}
import java.util.Properties

object TestMySQL
{
  def main(args: Array[String])
  {
    val conf = new SparkConf().setAppName("Student").setMaster("local")
    val sc = new SparkContext(conf)
    val spark = SparkSession.builder()
      .appName("Spark Sql basic example")
      .config("spark.some.config.option", "some-value")
      .getOrCreate()

    import spark.implicits._
    val employeeRDD = spark.sparkContext.parallelize(Array("3 Mary F 26", "4 Tom M 23")).map(_.split(" "))
    val schema = StructType(List(StructField("id", IntegerType, true), StructField("name", StringType, true), StructField("gender", StringType, true), StructField("age", IntegerType, true)))
    val rowRDD = employeeRDD.map(p => Row(p(0).toInt, p(1).trim, p(2).trim, p(3).toInt))
    val employeeDF = spark.createDataFrame(rowRDD, schema)
    val prop = new Properties()

    prop.put("user", "******")
    prop.put("password", "******")
    prop.put("driver", "com.mysql.jdbc.Driver")

    employeeDF.write.mode("append").jdbc("jdbc:mysql://localhost:3306/sparktest", "sparktest.employee", prop)

    val jdbcDF = spark.read.format ("jdbc").option ("url", "jdbc:mysql://localhost:3306/sparktest").option ("driver", "com.mysql.jdbc.Driver").option ("dbtable", "employee").option ("user", "******").option ("password", "******").load ()
      jdbcDF.agg ("age" -> "max", "age" -> "sum")
    }

}

```
